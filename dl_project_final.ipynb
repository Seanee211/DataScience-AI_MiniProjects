{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPool2D\n",
    "from keras.initializers import HeNormal, HeUniform\n",
    "from keras.regularizers import L1, L2, L1L2\n",
    "import tensorflow as tf\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_img(folder_path):\n",
    "\n",
    "#     file_list = os.listdir(folder_path)\n",
    "#     result_df = pd.DataFrame()\n",
    "#     result_arr = []\n",
    "#     for file in file_list:\n",
    "#         # json 파일 로드, 필요한 정보 추출\n",
    "#         with open(folder_path+file, 'r') as f: \n",
    "#             data = json.load(f)\n",
    "        \n",
    "#         # json 파일에서 파일명 읽어와 이미지 데이터 로드/300*400/0~1 정규화\n",
    "#         img_path = folder_path.replace('label','img') + data['imgName']\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img_resized_normed = (cv2.resize(img, (300,400))) / 255.\n",
    "#         result_arr.append(img_resized_normed)\n",
    "        \n",
    "#         # img를 df 변환, 라벨 추가\n",
    "#         df = pd.DataFrame([[data['item']['era'], data['item']['style'], data['user']['age'], data['user']['job'], data['user']['income']]])\n",
    "        \n",
    "#         # 최종 df 구축\n",
    "#         result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "\n",
    "#     result_df = result_df.rename(columns={0:'era', 1:'style', 2:'age', 3:'job', 4:'income'})\n",
    "#     result_arr_np=np.array(result_arr)\n",
    "        \n",
    "#     return [result_df,result_arr_np]\n",
    "\n",
    "\n",
    "# json_file1 = './label/1950/'\n",
    "# data_label_1950 = read_img(json_file1)[0]\n",
    "# data_label_1950.to_csv('data_1950.csv', index=False)\n",
    "# data_img_1950=read_img(json_file1)[1]\n",
    "# np.savez_compressed('data_1950.npz', images=data_img_1950)\n",
    "\n",
    "# json_file2 = './label/1960/'\n",
    "# data_label_1960 = read_img(json_file2)[0]\n",
    "# data_label_1960.to_csv('data_1960.csv', index=False)\n",
    "# data_img_1960=read_img(json_file2)[1]\n",
    "# np.savez_compressed('data_1960.npz', images=data_img_1960)\n",
    "\n",
    "# json_file3 = './label/2010/'\n",
    "# data_label_2010 = read_img(json_file3)[0]\n",
    "# data_label_2010.to_csv('data_2010.csv', index=False)\n",
    "# data_img_2010=read_img(json_file3)[1]\n",
    "# np.savez_compressed('data_2010.npz', images=data_img_2010)\n",
    "\n",
    "# json_file4 = './label/2019/'\n",
    "# data_label_2019 = read_img(json_file4)[0]\n",
    "# data_label_2019.to_csv('data_2019.csv', index=False)\n",
    "# data_img_2019=read_img(json_file4)[1]\n",
    "# np.savez_compressed('data_2019.npz', images=data_img_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_1950_ = np.load('./data_1950.npz')\n",
    "# data_1950_ = data_1950_['images'].astype(np.float16)\n",
    "# data_1960_ = np.load('./data_1960.npz')\n",
    "# data_1960_ = data_1960_['images'].astype(np.float16)\n",
    "# data_1970_ = np.load('./data_1970.npz')\n",
    "# data_1970_ = data_1970_['images'].astype(np.float16)\n",
    "# data_1980_ = np.load('./data_1980.npz')\n",
    "# data_1980_ = data_1980_['images'].astype(np.float16)\n",
    "# data_1990_ = np.load('./data_1990.npy')\n",
    "# data_1990_ = data_1990_.astype(np.float16)\n",
    "# data_2000_ = np.load('./data_2000.npy')\n",
    "# data_2000_ = data_2000_.astype(np.float16)\n",
    "# data_2010_ = np.load('./data_2010.npz')\n",
    "# data_2010_ = data_2010_['images'].astype(np.float16)\n",
    "# data_2019_ = np.load('./data_2019.npz')\n",
    "# data_2019_ = data_2019_['images'].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '../DL_PROJECT/'\n",
    "# file_list = os.listdir(file_dir)\n",
    "# final_df = pd.DataFrame([])\n",
    "\n",
    "# for file in file_list:\n",
    "#     if file.endswith('.csv'):\n",
    "#         df = pd.read_csv(f'{file_dir + file}')\n",
    "#         final_df = pd.concat([final_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('./all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>era</th>\n",
       "      <th>style</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>classic</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>classic</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1950</td>\n",
       "      <td>classic</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1950</td>\n",
       "      <td>classic</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1950</td>\n",
       "      <td>classic</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   era    style  age  job  income\n",
       "0           0  1950  classic    3    4       2\n",
       "1           1  1950  classic    2    3       2\n",
       "2           2  1950  classic    3    4       2\n",
       "3           3  1950  classic    3    1       5\n",
       "4           4  1950  classic    3    1       6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.get_dummies(final_df['job']).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label.to_numpy()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all = np.load('./all_16.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, test_x, train_y, test_y = train_test_split(data_all, label, stratify=label, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('train_x.npy', train_x)\n",
    "# np.save('test_x.npy', test_x)\n",
    "# np.save('train_y.npy', train_y)\n",
    "# np.save('test_y.npy', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = np.load('./train_x.npy')\n",
    "# train_x_resized_normed = (cv2.resize(train_x, (200,150)))\n",
    "# train_x\n",
    "# resized_images_x = []\n",
    "# for img in train_x:\n",
    "#     img = img.astype(np.float32) \n",
    "#     resized_img = cv2.resize(img, (200,150))\n",
    "#     resized_images_x.append(resized_img)\n",
    "# train_x_resized = np.array(resized_images_x)\n",
    "# np.save('train_x_resized.npy', train_x_resized)\n",
    "# train_x_resized = np.load('./train_x_resized.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = np.load('./train_y.npy')\n",
    "# train_y_resized_normed = (cv2.resize(train_y, (200,150)))\n",
    "# train_y\n",
    "# resized_images_y = []\n",
    "# for img in train_y:\n",
    "#     img = img.astype(np.float32) \n",
    "#     resized_img = cv2.resize(img, (200,150))\n",
    "#     resized_images_y.append(resized_img)\n",
    "# train_y_resized = np.array(resized_images_y)\n",
    "# np.save('train_y_resized.npy', train_y_resized)\n",
    "# train_y_resized = np.load('./train_y_resized.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential(name='Fashion_Job_Model')\n",
    "# model.add(Conv2D(32, 3, input_shape=(300,400, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Conv2D(64, 3, activation='relu'))\n",
    "# model.add(MaxPool2D())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(data, labels, batch_size):\n",
    "    num_samples = len(data)\n",
    "    while True:\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            yield data[start:end], labels[start:end]\n",
    "\n",
    "# train_gen = create_generator(train_x_resized, label, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "\n",
    "# # 학습 데이터용 generator 설정\n",
    "# train_generator = datagen.flow_from_directory(\n",
    "#     directory='../DL_PROJECT/train_x.npy',  # 이미지 경로\n",
    "#     target_size=(200, 150),           # 모든 이미지의 크기를 조정합니다.\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical',              # categorical_crossentropy 손실 함수를 사용하기 때문에 다중 레이블이 필요합니다.\n",
    "#     subset='training')                # 'validation'이 아니라 'training' 이미지를 생성하기 위해 사용됩니다.\n",
    "\n",
    "# # 검증 데이터용 generator 설정\n",
    "# validation_generator = datagen.flow_from_directory(\n",
    "#     directory='../DL_PROJECT/train_y.npy',  # 이미지 경로 \n",
    "#     target_size=(200, 150),           # 모든 이미지의 크기를 조정합니다.\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical',\n",
    "#     subset='validation')              # 'training'이 아니라 'validation' 이미지를 생성하기 위해 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_File = file_dir + 'cnn_fashion_model.h5'\n",
    "mcCB = ModelCheckpoint(m_File,\n",
    "                       save_best_only=True, monitor='val_loss')\n",
    "esCB = EarlyStopping(monitor='val_loss',patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fashion_Job_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 73, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 49, 36, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 23, 17, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 15, 1)         577       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 10, 7, 1)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 70)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 355       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 36        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20360 (79.53 KB)\n",
      "Trainable params: 20360 (79.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =Sequential(name='Fashion_Job_Model')\n",
    "# 기본값 : valid Padding, strides=(1,1)\n",
    "model.add(Conv2D(32, 3, input_shape=(100,75, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(1, 3, activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(len(label[0]), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(m_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_ = 30\n",
    "val_split = 0.25\n",
    "# batch_ = 50\n",
    "# result = model.fit(train_generator, validation_data=validation_generator, epochs=50)\n",
    "# train_x, val_x, train_y, val_y = train_test_split(data_all, label, stratify=label, test_size=val_split, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('train_x.npy', train_x)\n",
    "# np.save('val_x.npy', val_x)\n",
    "# np.save('train_y.npy', train_y)\n",
    "# np.save('val_y.npy', val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = np.load('./train_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = np.load('./train_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_resized = tf.image.resize(train_x, (100, 75))\n",
    "# np.save('train_x_resized_2.npy',train_x_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.load('./train_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = np.load('./val_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_x_resized = tf.image.resize(val_x, (100, 75))\n",
    "# np.save('val_x_resized_2.npy',val_x_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('train_x.npy', train_x)\n",
    "# np.save('val_x.npy', test_x)\n",
    "# np.save('train_y.npy', train_y)\n",
    "# np.save('val_y.npy', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_resized = np.load('./train_x_resized_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x_resized = np.load('./val_x_resized_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "527/527 [==============================] - ETA: 0s - loss: 1.6761 - accuracy: 0.2898"
     ]
    }
   ],
   "source": [
    "# 각각의 데이터셋에 대한 제너레이터 생성\n",
    "train_gen = create_generator(train_x_resized, train_y, batch_size=32)\n",
    "val_gen = create_generator(val_x_resized, val_y, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = model.fit(train_gen,\n",
    "          steps_per_epoch=len(train_x_resized) // 32,\n",
    "          epochs=50,\n",
    "          validation_data=val_gen,\n",
    "          callbacks=[mcCB, esCB],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.fit(x_train, y_train, \n",
    "#                    epochs=epochs_, \n",
    "#                    validation_split=val_split,\n",
    "#                     batch_size=batch_,\n",
    "#                     verbose=verbose_,\n",
    "#                     callbacks=[mcCB, esCB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
